<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Secci√≥n 2: Demostraciones Pr√°cticas</title>
    <link rel="stylesheet" href="../../reveal.js/dist/reset.css">
    <link rel="stylesheet" href="../../reveal.js/dist/reveal.css">
    <link rel="stylesheet" href="../../reveal.js/dist/theme/white.css">
    <link rel="stylesheet" href="../css/presentations.css">
</head>
<body>
    <!-- Header con t√≠tulo del curso -->
    <div class="presentation-header">
      Curso de Fine-Tuning
    </div>
    
    <!-- Logos -->
    <img src="../images/logo_left.png" alt="Logo FIUBA" class="presentation-logo-left">
    <img src="../images/logo_right.png" alt="Logo IngenIA UBA" class="presentation-logo-right">
    
    <!-- Footer con informaci√≥n de la facultad -->
    <div class="presentation-footer">
      Facultad de Ingenier√≠a Universidad de Buenos Aires (FIUBA) - Unidad de Capacitaci√≥n, Actualizaci√≥n y Perfeccionamiento (UCAP)
    </div>

    <div class="reveal">
        <div class="slides">


            <!-- ######################### -->
            <!-- ######## PARTE 0 ######## -->
            <!-- ######################### -->
            <!-- Slide 1: T√≠tulo -->
            <section data-background-image="../images/background.png" data-background-size="cover" data-background-position="center">
                <h1>Secci√≥n 2: Demostraciones Pr√°cticas</h1>
                <h3>Conceptos Fundamentales en Acci√≥n</h3>
                <p><small>Material de Soporte para el Curso de Fine-Tuning</small></p>
            </section>


            <!-- ######################### -->
            <!-- ######## PARTE 1 ######## -->
            <!-- ######################### -->
            <!-- Secci√≥n 1: Objetivos -->
            <section data-background-color="#C8F4FD" data-background-transition="zoom">
                <section data-background-color="#C8F4FD" data-background-transition="zoom">
                <h2><span class="emoji">üéØ</span> Objetivos de esta Secci√≥n</h2>
                <p>Al finalizar esta secci√≥n, los participantes podr√°n:</p>
                <ul>
                    <li>Comprender qu√© es un token de forma pr√°ctica</li>
                    <li>Repasar la estructura de prompts y respuestas</li>
                    <li>Diferenciar entre modelos base e instruidos</li>
                    <li>Observar el comportamiento de diferentes tipos de modelos</li>
                </ul>
                </section>
            </section>


            <!-- ######################### -->
            <!-- ######## PARTE 2 ######## -->
            <!-- ######################### -->
            <!-- Secci√≥n 2: Explorando Tokens -->
            <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">üîç</span> Explorando Tokens</h2>
                <h3>¬øQu√© es un Token? (Demostraci√≥n Pr√°ctica)</h3>
                <p><strong>¬øQu√© es un token?</strong></p>
                <ul>
                    <li>Es la <strong>unidad b√°sica</strong> que entiende el modelo</li>
                    <li>Puede ser una palabra completa, parte de una palabra, o s√≠mbolos</li>
                    <li>Los modelos "piensan" en tokens, no en letras o palabras</li>
                </ul>
                <div class="code-block">
                    <strong>Ejemplos pr√°cticos:</strong><br>
                    Texto: "¬°Hola mundo!"<br>
                    ¬øCu√°ntos tokens crees que son?
                </div>
                </section>
                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">üîß</span> Herramienta de Demostraci√≥n</h2>
                <p><strong>Herramienta de demostraci√≥n:</strong></p>
                <a href="https://tiktokenizer.vercel.app/" class="demo-link" target="_blank">
                    üîó https://tiktokenizer.vercel.app/
                </a>
                <h3>Actividad Pr√°ctica: Explorando Tokens</h3>
                <p><strong>Vamos a probar diferentes textos:</strong></p>
                <ol>
                    <li><strong>Texto simple en espa√±ol:</strong> "Hola, ¬øc√≥mo est√°s?"</li>
                    <li><strong>Texto con n√∫meros:</strong> "El a√±o 2024 tiene 366 d√≠as"</li>
                    <li><strong>Texto con emojis:</strong> "Me gusta la pizza üçï y el caf√© ‚òï"</li>
                    <li><strong>C√≥digo de programaci√≥n:</strong> <code>def saludar(nombre): return f"Hola, {nombre}!"</code></li>
                </ol>
                </section>

                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">üëÄ</span> ¬øQu√© observamos?</h2>
                <ul>
                    <li><strong>Palabras comunes</strong> = menos tokens</li>
                    <li><strong>Palabras raras</strong> = m√°s tokens</li>
                    <li><strong>N√∫meros</strong> = comportamiento especial</li>
                    <li><strong>Emojis</strong> = m√∫ltiples tokens</li>
                    <li><strong>C√≥digo</strong> = muchos tokens</li>
                </ul>
                </section>
            </section>


            <!-- ######################### -->
            <!-- ######## PARTE 3 ######## -->
            <!-- ######################### -->
            <!-- Secci√≥n 3: Estructura de Conversaci√≥n y Modelos Base vs Instruidos -->
            <section data-background-color="#FFF2E6" data-background-transition="zoom">
                <section data-background-color="#FFF2E6" data-background-transition="zoom">
                <h2><span class="emoji">üß†</span> Modelos Base vs Modelos Instruidos</h2>
                <h3>Recordemos c√≥mo funcionan los LLMs</h3>
                <p><strong>Los LLMs se entrenan con datos de texto:</strong></p>
                <ul>
                    <li><strong>Fuente principal:</strong> Internet (p√°ginas web, libros, art√≠culos)</li>
                    <li><strong>Objetivo original:</strong> Predecir el siguiente token</li>
                    <li><strong>Resultado:</strong> Saben hablar mucho y muy largo, pero no como un chat</li>
                </ul>
                </section>
                <section data-background-color="#FFF2E6" data-background-transition="zoom">
                <h2><span class="emoji">‚ùå</span> El Problema de los Modelos Base</h2>
                <h3>¬øQu√© hacen naturalmente?</h3>
                <ul>
                    <li>Completan texto</li>
                    <li>Contin√∫an historias</li>
                    <li>Siguen patrones</li>
                    <li><strong>NO conversan como humanos</strong></li>
                </ul>
                <div class="code-block">
                    <strong>Ejemplo de comportamiento:</strong><br>
                    Input: "El clima hoy est√°"<br>
                    Modelo Base: "El clima hoy est√° nublado. Seg√∫n el pron√≥stico meteorol√≥gico, se esperan lluvias durante la tarde. La temperatura m√°xima ser√° de 22¬∞C y la m√≠nima de 15¬∞C. Los vientos ser√°n del sureste con velocidades de 15 km/h..."
                </div>
                </section>
                <section data-background-color="#FFF2E6" data-background-transition="zoom">
                <h2><span class="emoji">‚úÖ</span> La Soluci√≥n: Fine-Tuning para Instrucciones</h2>
                <p><strong>Para llegar a un modelo que se parezca a un chat hay que hacer algo:</strong></p>
                <ul>
                    <li><strong>Ese algo es fine-tuning</strong></li>
                    <li>Espec√≠ficamente: <strong>Instruction Fine-Tuning</strong></li>
                    <li>Entrenar al modelo para seguir instrucciones</li>
                    <li>Ense√±arle a conversar como humano</li>
                </ul>
                </section>
            </section>


            <!-- ######################### -->
            <!-- ######## PARTE 4 ######## -->
            <!-- ######################### -->
            <!-- Secci√≥n 4: Demostraci√≥n Pr√°ctica -->
            <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">üî¨</span> Demostraci√≥n Pr√°ctica: Base vs Instruido</h2>
                <h3>Modelo Base - Llama 3.1 405B Base</h3>
                <a href="https://app.hyperbolic.ai/models/llama31-405b-base-bf-16" class="demo-link" target="_blank">
                    üîó https://app.hyperbolic.ai/models/llama31-405b-base-bf-16
                </a>
                <p><strong>Caracter√≠sticas:</strong></p>
                <ul>
                    <li><strong>Modelo original</strong> sin fine-tuning de instrucciones</li>
                    <li><strong>Completa texto</strong> en lugar de responder</li>
                    <li><strong>Comportamiento "crudo"</strong> del modelo</li>
                </ul>
                <div class="code-block">
                    <strong>Vamos a probar:</strong><br>
                    Prompt: "El capital de Francia es"<br>
                    ¬øQu√© esperamos que responda?
                </div>
                </section>
                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">ü§ñ</span> Modelo Instruido - Llama 3.1 405B Instruct</h2>
                <a href="https://app.hyperbolic.ai/models/llama31-405b" class="demo-link" target="_blank">
                    üîó https://app.hyperbolic.ai/models/llama31-405b
                </a>
                <p><strong>Caracter√≠sticas:</strong></p>
                <ul>
                    <li><strong>Mismo modelo base</strong> pero con fine-tuning</li>
                    <li><strong>Responde preguntas</strong> como un asistente</li>
                    <li><strong>Comportamiento conversacional</strong></li>
                </ul>
                <div class="code-block">
                    <strong>Vamos a probar:</strong><br>
                    Prompt: "¬øCu√°l es la capital de Francia?"<br>
                    ¬øQu√© diferencia esperamos ver?
                </div>
                </section>
                <section data-background-color="#F0F8F0" data-background-transition="zoom">
                <h2><span class="emoji">üîÑ</span> Actividad de Comparaci√≥n</h2>
                <p><strong>Prompts para probar en ambos modelos:</strong></p>
                <ol>
                    <li><strong>Completar texto:</strong> "La inteligencia artificial es"</li>
                    <li><strong>Pregunta directa:</strong> "¬øQu√© es la inteligencia artificial?"</li>
                    <li><strong>Instrucci√≥n espec√≠fica:</strong> "Explica en 3 puntos qu√© es el machine learning"</li>
                    <li><strong>Conversaci√≥n:</strong> "Hola, ¬øpuedes ayudarme?"</li>
                </ol>
                </section>
            </section>

            <!-- ######################### -->
            <!-- ######## PARTE 5 ######## -->
            <!-- ######################### -->
            <!-- Secci√≥n 5: Conclusiones -->
            <section data-background-color="#E8F4FD" data-background-transition="zoom">
                <section data-background-color="#E8F4FD" data-background-transition="zoom">
                <h2><span class="emoji">üìä</span> ¬øQu√© diferencias observamos?</h2>
                <div class="two-columns">
                    <div class="column">
                        <h3><strong>Modelo Base:</strong></h3>
                        <ul>
                            <li>‚úÖ Excelente para completar texto</li>
                            <li>‚úÖ Muy creativo y fluido</li>
                            <li>‚ùå No sigue instrucciones espec√≠ficas</li>
                            <li>‚ùå No conversa como humano</li>
                            <li>‚ùå Puede generar texto irrelevante</li>
                        </ul>
                    </div>
                    <div class="column">
                        <h3><strong>Modelo Instruido:</strong></h3>
                        <ul>
                            <li>‚úÖ Sigue instrucciones precisas</li>
                            <li>‚úÖ Conversa naturalmente</li>
                            <li>‚úÖ Respuestas estructuradas</li>
                            <li>‚úÖ Se comporta como asistente</li>
                            <li>‚ùå Menos creativo en algunos casos</li>
                        </ul>
                    </div>
                </div>
                </section>
                <section data-background-color="#E8F4FD" data-background-transition="zoom">
                <h2><span class="emoji">üéØ</span> Conclusiones de las Demostraciones</h2>
                <h3>Lo que aprendimos:</h3>
                <ol>
                    <li><strong>Tokens son fundamentales</strong>
                        <ul>
                            <li>Todo texto se convierte en tokens</li>
                            <li>Diferentes idiomas = diferentes patrones</li>
                            <li>Importante para entender costos y l√≠mites</li>
                        </ul>
                    </li>
                    <li><strong>Estructura de conversaci√≥n</strong>
                        <ul>
                            <li>System, User, Assistant tienen roles espec√≠ficos</li>
                            <li>El formato es crucial para el comportamiento</li>
                            <li>La calidad del prompt afecta la respuesta</li>
                        </ul>
                    </li>
                </ol>
                </section>
                <section data-background-color="#E8F4FD" data-background-transition="zoom">
                <h2><span class="emoji">üîÑ</span> Fine-tuning Transforma Modelos</h2>
                <ul>
                    <li><strong>Mismo modelo base</strong> ‚Üí comportamientos diferentes</li>
                    <li><strong>Instruction tuning</strong> crea asistentes conversacionales</li>
                    <li>Es la diferencia entre <strong>"completar"</strong> y <strong>"responder"</strong></li>
                </ul>
                <h3>Pr√≥ximos pasos:</h3>
                <ul>
                    <li>En las siguientes secciones veremos c√≥mo hacer nuestro propio fine-tuning</li>
                    <li>Aprenderemos a preparar datos de entrenamiento</li>
                    <li>Usaremos herramientas pr√°cticas para el proceso</li>
                </ul>
                </section>
                <section data-background-color="#E8F4FD" data-background-transition="zoom">
                <h2><span class="emoji">ü§î</span> Preguntas para Reflexionar</h2>
                <ol>
                    <li>¬øPor qu√© crees que es importante entender los tokens?</li>
                    <li>¬øEn qu√© situaciones usar√≠as un modelo base vs uno instruido?</li>
                    <li>¬øQu√© ventajas y desventajas ves en cada tipo de modelo?</li>
                    <li>¬øC√≥mo crees que el fine-tuning puede mejorar un modelo para tu caso espec√≠fico?</li>
                </ol>
                </section>
            </section>


            <!-- ######################### -->
            <!-- ######## PARTE Z ######## -->
            <!-- ######################### -->
            <!-- Slides Finales -->
            <section data-background-image="../images/background.png" data-background-size="cover" data-background-position="center">
                <section data-background-image="../images/background.png" data-background-size="cover" data-background-position="center">
                    <h2><span class="emoji">üìö</span> Recursos Adicionales</h2>
                    <h3>Herramientas mencionadas:</h3>
                    <ul>
                        <li><strong>Tiktokenizer:</strong> <a href="https://tiktokenizer.vercel.app/" target="_blank">https://tiktokenizer.vercel.app/</a></li>
                        <li><strong>Llama 3.1 405B Base:</strong> <a href="https://app.hyperbolic.ai/models/llama31-405b-base-bf-16" target="_blank">https://app.hyperbolic.ai/models/llama31-405b-base-bf-16</a></li>
                        <li><strong>Llama 3.1 405B Instruct:</strong> <a href="https://app.hyperbolic.ai/models/llama31-405b" target="_blank">https://app.hyperbolic.ai/models/llama31-405b</a></li>
                    </ul>
                    <h3>Para explorar m√°s:</h3>
                    <ul>
                        <li>Prueba diferentes tipos de texto en el tokenizador</li>
                        <li>Experimenta con ambos modelos usando diferentes prompts</li>
                        <li>Observa c√≥mo cambia el comportamiento seg√∫n el tipo de entrada</li>
                    </ul>
                </section>

                <section data-background-image="../images/background.png" data-background-size="cover" data-background-position="center">
                    <h2><span class="emoji">üéâ</span> ¬°Gracias!</h2>
                    <p>¬øPreguntas sobre las demostraciones pr√°cticas?</p>
                    <p><small>Pr√≥xima secci√≥n: Herramientas para Fine-Tuning</small></p>
                </section>
            </section>
        </div>
    </div>

    <script src="../../reveal.js/dist/reveal.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            transition: 'slide',
            transitionSpeed: 'default',
            backgroundTransition: 'fade'
        });
        
        // Los colores de fondo se aplican directamente con data-background-color
    </script>
</body>
</html>
