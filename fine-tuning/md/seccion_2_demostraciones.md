# SecciÃ³n 2: Demostraciones PrÃ¡cticas

## Material de Soporte para el Curso de Fine-Tuning

---

# 2.1 Conceptos Fundamentales en AcciÃ³n

## ğŸ¯ Objetivos de esta SecciÃ³n

Al finalizar esta secciÃ³n, los participantes podrÃ¡n:
- Comprender quÃ© es un token de forma prÃ¡ctica
- Repasar la estructura de prompts y respuestas
- Diferenciar entre modelos base e instruidos
- Observar el comportamiento de diferentes tipos de modelos

---

## ğŸ” Explorando Tokens

### **Â¿QuÃ© es un Token? (DemostraciÃ³n PrÃ¡ctica)**

**Nota importante:**
- No es estrictamente fine-tuning, pero estÃ¡ bueno que lo vean
- Es fundamental entender estos conceptos bÃ¡sicos

### **Vamos a ver quÃ© es un token**

**Â¿QuÃ© es un token?**
- Es la **unidad bÃ¡sica** que entiende el modelo
- Puede ser una palabra completa, parte de una palabra, o sÃ­mbolos
- Los modelos "piensan" en tokens, no en letras o palabras

**Ejemplos prÃ¡cticos:**
```
Texto: "Â¡Hola mundo!"
Â¿CuÃ¡ntos tokens crees que son?
```

**Herramienta de demostraciÃ³n:**
ğŸ”— **https://tiktokenizer.vercel.app/**

----

### **Actividad PrÃ¡ctica: Explorando Tokens**

**Vamos a probar diferentes textos:**

1. **Texto simple en espaÃ±ol:**
   ```
   "Hola, Â¿cÃ³mo estÃ¡s?"
   ```

2. **Texto con nÃºmeros:**
   ```
   "El aÃ±o 2024 tiene 366 dÃ­as"
   ```

3. **Texto con emojis:**
   ```
   "Me gusta la pizza ğŸ• y el cafÃ© â˜•"
   ```

4. **CÃ³digo de programaciÃ³n:**
   ```python
   def saludar(nombre):
       return f"Hola, {nombre}!"
   ```

----

**Â¿QuÃ© observamos?**
- Palabras comunes = menos tokens
- Palabras raras = mÃ¡s tokens
- NÃºmeros = comportamiento especial
- Emojis = mÃºltiples tokens
- CÃ³digo = muchos tokens

---

## ğŸ’¬ Estructura de ConversaciÃ³n con IA

### **Vamos a repasar un prompt y respuesta**

**Estructura bÃ¡sica de una conversaciÃ³n:**

#### **1. System (Sistema)**
```
Rol: Define el comportamiento del asistente
Ejemplo: "Eres un profesor experto en inteligencia artificial"
```

#### **2. User (Usuario)**
```
Rol: La pregunta o instrucciÃ³n del usuario
Ejemplo: "ExplÃ­came quÃ© es el fine-tuning"
```

#### **3. Assistant (Asistente)**
```
Rol: La respuesta del modelo
Ejemplo: "El fine-tuning es un proceso donde..."
```

---

## ğŸ§  Modelos Base vs Modelos Instruidos

### **Recordemos cÃ³mo funcionan los LLMs**

**Los LLMs se entrenan con datos de texto:**
- **Fuente principal:** Internet (pÃ¡ginas web, libros, artÃ­culos)
- **Objetivo original:** Predecir el siguiente token
- **Resultado:** Saben hablar mucho y muy largo, pero no como un chat

### **El Problema de los Modelos Base**

**Â¿QuÃ© hacen naturalmente?**
- Completan texto
- ContinÃºan historias
- Siguen patrones
- **NO conversan como humanos**

**Ejemplo de comportamiento:**
```
Input: "El clima hoy estÃ¡"
Modelo Base: "El clima hoy estÃ¡ nublado. SegÃºn el pronÃ³stico 
meteorolÃ³gico, se esperan lluvias durante la tarde. La temperatura 
mÃ¡xima serÃ¡ de 22Â°C y la mÃ­nima de 15Â°C. Los vientos serÃ¡n del 
sureste con velocidades de 15 km/h..."
```

----

### **La SoluciÃ³n: Fine-Tuning para Instrucciones**

**Para llegar a un modelo que se parezca a un chat hay que hacer algo:**
- **Ese algo es fine-tuning**
- EspecÃ­ficamente: **Instruction Fine-Tuning**
- Entrenar al modelo para seguir instrucciones
- EnseÃ±arle a conversar como humano

---

## ğŸ”¬ DemostraciÃ³n PrÃ¡ctica: Base vs Instruido

### **Modelo Base - Llama 3.1 405B Base**

ğŸ”— **https://app.hyperbolic.ai/models/llama31-405b-base-bf-16**

**CaracterÃ­sticas:**
- **Modelo original** sin fine-tuning de instrucciones
- **Completa texto** en lugar de responder
- **Comportamiento "crudo"** del modelo

**Vamos a probar:**
```
Prompt: "El capital de Francia es"
Â¿QuÃ© esperamos que responda?
```

----

### **Modelo Instruido - Llama 3.1 405B Instruct**

ğŸ”— **https://app.hyperbolic.ai/models/llama31-405b**

**CaracterÃ­sticas:**
- **Mismo modelo base** pero con fine-tuning
- **Responde preguntas** como un asistente
- **Comportamiento conversacional**

**Vamos a probar:**
```
Prompt: "Â¿CuÃ¡l es la capital de Francia?"
Â¿QuÃ© diferencia esperamos ver?
```

----

### **Actividad de ComparaciÃ³n**

**Prompts para probar en ambos modelos:**

1. **Completar texto:**
   ```
   "La inteligencia artificial es"
   ```

2. **Pregunta directa:**
   ```
   "Â¿QuÃ© es la inteligencia artificial?"
   ```

3. **InstrucciÃ³n especÃ­fica:**
   ```
   "Explica en 3 puntos quÃ© es el machine learning"
   ```

4. **ConversaciÃ³n:**
   ```
   "Hola, Â¿puedes ayudarme?"
   ```

### **Â¿QuÃ© diferencias observamos?**

**Modelo Base:**
- âœ… Excelente para completar texto
- âœ… Muy creativo y fluido
- âŒ No sigue instrucciones especÃ­ficas
- âŒ No conversa como humano
- âŒ Puede generar texto irrelevante

**Modelo Instruido:**
- âœ… Sigue instrucciones precisas
- âœ… Conversa naturalmente
- âœ… Respuestas estructuradas
- âœ… Se comporta como asistente
- âŒ Menos creativo en algunos casos

---

## ğŸ¯ Conclusiones de las Demostraciones

### **Lo que aprendimos:**

1. **Tokens son fundamentales**
   - Todo texto se convierte en tokens
   - Diferentes idiomas = diferentes patrones
   - Importante para entender costos y lÃ­mites

2. **Estructura de conversaciÃ³n**
   - System, User, Assistant tienen roles especÃ­ficos
   - El formato es crucial para el comportamiento
   - La calidad del prompt afecta la respuesta

3. **Fine-tuning transforma modelos**
   - Mismo modelo base â†’ comportamientos diferentes
   - Instruction tuning crea asistentes conversacionales
   - Es la diferencia entre "completar" y "responder"

----

### **PrÃ³ximos pasos:**
- En las siguientes secciones veremos cÃ³mo hacer nuestro propio fine-tuning
- Aprenderemos a preparar datos de entrenamiento
- Usaremos herramientas prÃ¡cticas para el proceso

---

## ğŸ¤” Preguntas para Reflexionar

1. **Â¿Por quÃ© crees que es importante entender los tokens?**
2. **Â¿En quÃ© situaciones usarÃ­as un modelo base vs uno instruido?**
3. **Â¿QuÃ© ventajas y desventajas ves en cada tipo de modelo?**
4. **Â¿CÃ³mo crees que el fine-tuning puede mejorar un modelo para tu caso especÃ­fico?**

---

## ğŸ“š Recursos Adicionales

### **Herramientas mencionadas:**
- **Tiktokenizer:** https://tiktokenizer.vercel.app/
- **Llama 3.1 405B Base:** https://app.hyperbolic.ai/models/llama31-405b-base-bf-16
- **Llama 3.1 405B Instruct:** https://app.hyperbolic.ai/models/llama31-405b

### **Para explorar mÃ¡s:**
- Prueba diferentes tipos de texto en el tokenizador
- Experimenta con ambos modelos usando diferentes prompts
- Observa cÃ³mo cambia el comportamiento segÃºn el tipo de entrada

---

*Esta secciÃ³n prepara el terreno para entender por quÃ© el fine-tuning es necesario y cÃ³mo transforma el comportamiento de los modelos.*
